{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Dataframe\n",
    "\n",
    "\n",
    "The features of Pandas that make it indispensable:\n",
    "\n",
    "To be able to harness the true power of something as versatile as the Pandas library, one should know the following features.\n",
    "1. Great data handling\n",
    "2. Handling of missing data\n",
    "3. Indexing and Alignment\n",
    "4. Tools for input and output\n",
    "5. Data clean-up\n",
    "6. Support for multiple file formats\n",
    "7. Multiple features for Time Series\n",
    "8. Joining and Merging Datasets\n",
    "9. Support for Python\n",
    "10. Optimal performance\n",
    "11. Grouping of data\n",
    "12. Visualization of data\n",
    "13. Data is Unique\n",
    "14. Masking data\n",
    "15. Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame manually from a dictionary of Pandas Series\n",
    "\n",
    "# create a dictionary of Pandas Series \n",
    "items = {'Bob' : pd.Series(data = [245, 25, 55], index = ['bike', 'pants', 'watch']),\n",
    "         'Alice' : pd.Series(data = [40, 110, 500, 45], index = ['book', 'glasses', 'bike', 'pants'])}\n",
    "\n",
    "# print the type of items to see that it is a dictionary\n",
    "print(type(items)) # class 'dict'\n",
    "\n",
    "# create a Pandas DataFrame by passing it a dictionary of Series\n",
    "shopping_carts = pd.DataFrame(items)\n",
    "shopping_carts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame that only has a subset of the data/columns\n",
    "bob_shopping_cart = pd.DataFrame(items, columns=['Bob'])\n",
    "\n",
    "# create a DataFrame that only has selected keys\n",
    "sel_shopping_cart = pd.DataFrame(items, index = ['pants', 'book'])\n",
    "\n",
    "# combine both of the above - selected keys for selected columns\n",
    "alice_sel_shopping_cart = pd.DataFrame(items, index = ['glasses', 'bike'], columns = ['Alice'])\n",
    "\n",
    "print('shopping_carts has shape:', shopping_carts.shape)\n",
    "print('shopping_carts has dimension:', shopping_carts.ndim)\n",
    "print('shopping_carts has a total of:', shopping_carts.size, 'elements')\n",
    "print()\n",
    "print('The data in shopping_carts is:\\n', shopping_carts.values)\n",
    "print()\n",
    "print('The row index in shopping_carts is:', shopping_carts.index)\n",
    "print()\n",
    "print('The column index in shopping_carts is:', shopping_carts.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrames from a dictionary of lists (arrays)\n",
    "# In this case, however, all the lists (arrays) in the dictionary must be of the same length\n",
    "\n",
    "# create a dictionary of lists (arrays)\n",
    "data = {'Integers' : [1,2,3],\n",
    "        'Floats' : [4.5, 8.2, 9.6]}\n",
    "\n",
    "# create a DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# create a DataFrame and provide the row index\n",
    "df = pd.DataFrame(data, index = ['label 1', 'label 2', 'label 3'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrames from a list of Python dictionaries\n",
    "# create a list of Python dictionaries\n",
    "items2 = [{'bikes': 20, 'pants': 30, 'watches': 35}, \n",
    "          {'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5}]\n",
    "\n",
    "# create a DataFrame \n",
    "store_items = pd.DataFrame(items2)\n",
    "\n",
    "# create a DataFrame and provide the row index\n",
    "store_items = pd.DataFrame(items2, index = ['store 1', 'store 2'])\n",
    "store_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data into DF\n",
    "filename = '../data/data.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# limit which rows are read when reading in a file\n",
    "pd.read_csv(filename, nrows=10)        \n",
    "# only read first 10 rows\n",
    "\n",
    "pd.read_csv(filename, skiprows=[1, 2]) \n",
    "# skip the first two rows of data\n",
    "\n",
    "# randomly sample a DataFrame\n",
    "train = df.sample(frac=0.75) \n",
    "# will contain 75% of the rows\n",
    "\n",
    "test = df[~df.index.isin(train.index)] \n",
    "# will contain the other 25%\n",
    "\n",
    "# change the maximum number of rows and columns printed ('None' means unlimited)\n",
    "pd.set_option('display.max_rows', None) \n",
    "# default is 60 rows\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "# default is 20 columns\n",
    "# print (df)\n",
    "\n",
    "# reset options to defaults\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "# change the options temporarily (settings are restored when you exit the ‘with’ block)\n",
    "#with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN values (missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with NaN values (missing data)\n",
    "\n",
    "# create a list of Python dictionaries\n",
    "items2 = [{'bikes': 20, 'pants': 30, 'watches': 35, 'shirts': 15, 'shoes':8, 'suits':45},\n",
    "{'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5, 'shirts': 2, 'shoes':5, 'suits':7},\n",
    "{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4, 'shoes':10}]\n",
    "\n",
    "# We create a DataFrame and provide the row index\n",
    "store_items = pd.DataFrame(items2, index = ['store 1', 'store 2', 'store 3'])\n",
    "\n",
    "# check if we have any NaN values in our dataset\n",
    "# .any() performs an or operation. If any of the values along the\n",
    "# specified axis is True, this will return True.\n",
    "df.isnull().any()\n",
    "'''\n",
    "Date   False\n",
    "Open   True\n",
    "High   False\n",
    "Low    False\n",
    "Close  False\n",
    "Volume False\n",
    "dtype: bool\n",
    "'''\n",
    "\n",
    "# count the number of NaN values in DataFrame\n",
    "x =  store_items.isnull().sum().sum()\n",
    "print(\"Number of NaN values is:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of non-NaN values in DataFrame\n",
    "x = store_items.count()\n",
    "print(\"Number of non-NaN values is:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows or columns from our DataFrame that contain any NaN values\n",
    "\n",
    "# drop any rows with NaN values\n",
    "new_store = store_items.dropna(axis = 0)\n",
    "\n",
    "print(store_items)\n",
    "print(\"\\n\")\n",
    "print(new_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any columns with NaN values\n",
    "new_store = store_items.dropna(axis = 1)\n",
    "\n",
    "print(store_items)\n",
    "print(\"\\n\")\n",
    "print(new_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_store = store_items.copy()\n",
    "# the original DataFrame is not modified by default\n",
    "# to remove missing values from original df, use inplace = True\n",
    "store_items.dropna(axis = 0, inplace = True)\n",
    "\n",
    "print(store_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_store)\n",
    "# replace all NaN values with 0\n",
    "original_store.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward filling: replace NaN values with previous values in the df,\n",
    "# this is known as . When replacing NaN values with forward filling,\n",
    "# we can use previous values taken from columns or rows.\n",
    "# replace NaN values with the previous value in the column\n",
    "original_store.fillna(method = 'ffill', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward filling: replace the NaN values with the values that\n",
    "# go after them in the DataFrame\n",
    "# replace NaN values with the next value in the row\n",
    "original_store.fillna(method = 'backfill', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values by using linear interpolation using column values\n",
    "original_store.interpolate(method = 'linear', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original DataFrame is not modified. replace the NaN values\n",
    "# in place by setting inplace = True inside function\n",
    "original_store.fillna(method = 'ffill', axis = 0, inplace = True)\n",
    "original_store.interpolate(method = 'linear', axis = 0, inplace = True)\n",
    "original_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## head, tail, describe, max, memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.tail()\n",
    "data.describe()\n",
    "# prints max value in each column\n",
    "data.max()\n",
    "\n",
    "# display the memory usage of a DataFrame\n",
    "\n",
    "# total usage\n",
    "data.info()\n",
    "\n",
    "# usage by column\n",
    "data.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation between different columns\n",
    "data.corr().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Groupby\n",
    "data.groupby(['diagnosis'])\n",
    "data.groupby(['diagnosis'])['id']\n",
    "\n",
    "# display the average radius_mean per diagnosis type\n",
    "print(data.groupby(['diagnosis'])['radius_mean'].mean())\n",
    "\n",
    "# display the total radius mean by diagnosis type\n",
    "print(data.groupby(['diagnosis'])['radius_mean'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Replace Values\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
    "print(s)\n",
    "s.map({'cat': 'kitten', 'dog': 'puppy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data using Labels (Column Headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index is :\", data[(data.radius_mean == 20.29)].index.values)\n",
    "\n",
    "datadict = data.to_dict()\n",
    "\n",
    "data_1 = datadict[\"texture_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data[[\"texture_mean\", \"concavity_mean\", \"diagnosis\"]]\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data[0:3]\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data[-1:]\n",
    "data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Objects vs Referencing Objects in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 'copy() method'\n",
    "true_copy_data = data.copy()\n",
    "\n",
    "# Using the '=' operator\n",
    "ref_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_copy_data[0:3] = 0\n",
    "\n",
    "true_copy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the value `0` to the first three rows of data in the DataFrame\n",
    "ref_data[0:3] = 0\n",
    "\n",
    "ref_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python\n",
    "- We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "    - loc is primarily label based indexing. Integers may be used but they are interpreted as a label.\n",
    "    - iloc is primarily integer based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n",
    "#data.iloc[row, col]\n",
    "data.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n",
    "data.loc[[0, 10], [\"id\",\"diagnosis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n",
    "data.loc[[0, 10], \"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n",
    "data.loc[[0,6], [\"id\", \"compactness_mean\", \"area_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.diagnosis == \"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.area_mean < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.diagnosis == \"M\") & (data.area_mean > 1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data.loc[0, [\"diagnosis\"]] = np.NaN\n",
    "data.loc[1, [\"diagnosis\"]] = np.NaN\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values, we can use the 'any()' method\n",
    "data[pd.isnull(data).any(axis=1)]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
